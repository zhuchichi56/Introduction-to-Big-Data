

#### 一.常用代码介绍：

##### class sklearn.impute.SimpleImputer(*, missing_values=nan, strategy=‘mean’, fill_value=None, verbose=0, copy=True, add_indicator=False)

```python
#missing_values：int, float, str, (默认)np.nan或是None, 即缺失值是什么。

#strategy：空值填充的策略，共四种选择（默认）mean、median、most_frequent、constant。mean表示该列的缺失值由该列的均值填充。
#median为中位数，most_frequent为众数。constant表示将空值填充为自定义的值，但这个自定义的值要通过fill_value来定义。

#fill_value：str或数值，默认为Zone。当strategy == "constant"时，fill_value被用来替换所有出现的缺失值（missing_values）fill_value为Zone，当处理的是数值数据时，缺失值（missing_values）会替换为0，对于字符串或对象数据类型则替换为"missing_value" 这一字符串。
#verbose：int，（默认）0，控制imputer的冗长。
#copy：boolean，（默认）True，表示对数据的副本进行处理，False对数据原地修改。
#add_indicator：boolean，（默认）False，True则会在数据后面加入n列由0和1构成的同样大小的数据，0表示所在位置非缺失值，1表示所在位
```

```python

X1 = np.array([[1, 2, np.nan],
               [4, np.nan, 6],
               [np.nan, 8, 9]])
imp = SimpleImputer(missing_values=np.nan, strategy='mean')
print(imp.fit_transform(X1))

# 运行结果
[[1.  2.  7.5]
 [4.  5.  6. ]
 [2.5 8.  9. ]]

```



#### 二.制造缺失值：

```python
i1 = np.random.choice(a=df.index, size=35)
i2 = np.random.choice(a=df.index, size=20)
df.loc[i1, 'INDUS'] = np.nan
df.loc[i2, 'TAX'] = np.nan
```



```python
n_samples = data.shape[0]#样本数量
n_features = data.shape[1]#标签数量
rng = np.random.RandomState(0)
missing_rate = 0.5
n_missing_samples = int(np.floor(n_samples * n_features *missing_rate))
missing_features = rng.randint(0,n_features,n_missing_samples)
missing_samples =rng.randint(0,n_samples,n_missing_samples)
#我们可以采用np.random.choice，choice会随机抽取不重复机数
##因此可以帮助我们让数据更加分散，确保数据不会集中在一些行中
x_missing = data.copy()
y_missing = data.copy()
x_missing[missing_samples,missing_features] = np.nan
x_missing = pd.DataFrame(x_missing)

#转换成DataFrame时为了后面方便操作，索引方便
```





#### 三.state-of-art的方法：

怎么填,这得看具体的数据情况,大部分缺失值填充算法:以randomforest为核心的missforest算法, 线性回归为核心的MICE,还有期望最大化,KNN等, 都基于一个假设就是:数据是随机缺失的,且特征之间具有相关性,这种情况的话,用missforest或者MICE都能达到一个不错的效果. 直接填充0,均值得话,效果一般都会很差; EM算法。

目前state-of-art的方法是用生成对抗网络生成合理的数据分布来做这件事情. 

我看了下生成对抗网络填充办法，应该是一个处理完全随机缺失的算法吧。

##### 1.拉格朗日缺失值的填充：

###### #这个暂时不是很懂原理

根据数学概念可知，对于平面上已知的n个点（无两点在一条直线上）可以找到一个n-1次的多项式，使此多项式通过这n个点。

因此我们需先求得多项式函数L(x)，然后将缺失值对应的点x带入插值多项式得到缺失值的近似值L(x)。

```python
def ployinterp_column(series, pos, window=5):
    """
    :param series: 列向量
    :param pos: 被插值的位置
    :param window: 为取前后的数据个数
    :return:
    """
    y = series[list(range(pos - window, pos)) + list(range(pos + 1, pos + 1 + window))]  # 取数
    y = y[y.notnull()]  # 剔除空值
    return lagrange(y.index, list(y))(pos)  # 插值并返回插值结果
```

```python
for j in range(len(tmp_data_1)):
    if (tmp_data_1.isnull())[j]:  # 如果为空即插值。
        tmp_data_1[j] = ployinterp_column(tmp_data_1, j)
        print (j, data.loc[j, u'日期'], tmp_data_1[j])
```



##### 2.随机森林填充：

https://blog.csdn.net/sjjsaaaa/article/details/110141936

<img src="/Users/zhuhe/Library/Application Support/typora-user-images/image-20220529151043737.png" alt="image-20220529151043737" style="zoom:50%;" />

思路是比较简单的，那么对于稍微复杂一点的情况，数据集有多个指标缺失，就需要以下几个步骤：

1. 按照缺失程度对需要填充的变量进行排序，从缺失率小的变量先开始填充；

2. 除了本次需要填充的目标变量，其他缺失值先用均值/中位数进行填充，再使用MissForest算法对目标变量的缺失值进行预测；

3. 将已经填充过的变量的缺失值（或者缺失位置的均值/中位数）用预测值代替，进入下一个变量的填充；

4. 直到所有的变量都已经填充过一遍，进入下一次迭代，由于缺失位置的值发生了改变，因此预测值也会随之发生变化；

5. ##### 当预测值收敛，本次迭代与上次迭代的预测值之差小于一定阈值时，迭代停止，缺失值填充完成。

 missForest虽然是一个效果比较好的缺失值填充方法，但是当数据集非常大的时候，效率也肉眼可见的非常低。因此具体使用哪种方法处理缺失值，还要看实际的情况了。

```python
from sklearn.ensemble import RandomForestRegressor
text_with_Randomforest_final = text.copy()
text_with_Randomforest  = text.copy()


Y = text['pm2.5']
del text_with_Randomforest['pm2.5']

y_train = Y[Y.notnull()]
y_test = Y[Y.isna()]
x_train = text_with_Randomforest.iloc[y_train.index,:]
x_test = text_with_Randomforest.iloc[y_test.index,:]

rfc = RandomForestRegressor(n_estimators=100)
rfc = rfc.fit(x_train,y_train)  
Ypredict = rfc.predict(x_test)

text_with_Randomforest_final['pm2.5'] =text_with_Randomforest_final['pm2.5'].astype('float')
text_with_Randomforest_final.loc[text_with_Randomforest_final['pm2.5'].isnull(),'pm2.5'] = Ypredict
text_with_Randomforest_final

```

<img src="/Users/zhuhe/Library/Application Support/typora-user-images/image-20220530113912870.png" alt="image-20220530113912870" style="zoom:50%;" />



##### 3.KNN进行填充：

https://www.zhihu.com/search?type=content&q=KNNImputer



```python
from sklearn.impute import KNNImputer

def optimize_k(data, target):    
errors = []    
for k in range(1, 20, 2):     
   imputer = KNNImputer(n_neighbors=k)      
   imputed = imputer.fit_transform(data)      
   df_imputed = pd.DataFrame(imputed, columns=df.columns)  
   X = df_imputed.drop(target, axis=1)      
   y = df_imputed[target]      
   X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)   
   model = RandomForestRegressor()    
   model.fit(X_train, y_train)     
   preds = model.predict(X_test)      
   error = rmse(y_test, preds)        
   errors.append({'K': k, 'RMSE': error})  
   return errors
```

###### imputer = KNNImputer(n_neighbors=1):

<img src="/Users/zhuhe/Library/Application Support/typora-user-images/image-20220529152305779.png" alt="image-20220529152305779" style="zoom:50%;" />

可以看到，因为第二个样本的第一列特征3和第三列特征7，与第一行样本的第一列特征2和第三列特征8的欧氏距离最近，所以缺失值按照第一个样本来填充，填充值为4。那么n_neighbors=2呢？

###### imputer = KNNImputer(n_neighbors=2):

<img src="https://www.freesion.com/images/181/a135a72210983f2aae33548a4105f94d.png" alt="a135a72210983f2aae33548a4105f94d" style="zoom:50%;" />

此时根据欧氏距离算出最近相邻的是第一行样本与第四行样本，此时的填充值就是这两个样本第二列特征4和3的均值：3.5。

缺失值样本的填充





##### 4.滑动平均窗口法

一个列表a 中的第 i 个位置数据为缺失数据，则取前后 window 个数据的平均值，作为插补数据。

```python
def sma_mothod(series, pos, window=5):
    """
    :param series: 列向量
    :param pos: 被插值的位置
    :param window: 为取前后的数据个数
    :return:
    """
    y = series[list(range(pos - window, pos)) + list(range(pos + 1, pos + 1 + window))]  # 取数
    y = y[y.notnull()]
    return reduce(lambda a, b: a + b, y) / len(y)
```

```python
for j in range(len(tmp_data_1)):
    if (tmp_data_1.isnull())[j]:  # 如果为空即插值。
        tmp_data_1[j] = sma_mothod(tmp_data_1, j)
        print (j, data.loc[j, u'日期'], tmp_data_1[j])
```













